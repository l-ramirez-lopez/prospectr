<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>An Introduction to the <code>prospectr</code> package</title>



<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<style type="text/css">

</style>

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- jQuery -->
<script src="http://cdnjs.cloudflare.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script src="http://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.10.2/jquery-ui.min.js"></script>

<!-- bootstrap -->
<link rel="stylesheet" type="text/css" href=http://netdna.bootstrapcdn.com/twitter-bootstrap/2.3.0/css/bootstrap-combined.min.css id="style" media="screen">
<script src="http://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/2.3.1/js/bootstrap.min.js"></script>

<!-- bootstrap-responsive -->
<link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/2.3.1/css/bootstrap-responsive.min.css" media="screen">

<!-- highlight.js -->
<link rel="stylesheet" href="http://yandex.st/highlightjs/7.3/styles/default.min.css">
<script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/7.3/highlight.min.js"></script>
<script src="http://yandex.st/highlightjs/7.3/languages/r.min.js"></script>

<!-- tocify -->
<script src="http://gregfranko.com/jquery.tocify.js/js/jquery.tocify.min.js"></script>

<!-- Manific Popup -->
<script src="http://dimsemenov.com/plugins/magnific-popup/dist/jquery.magnific-popup.min.js"></script>
<link rel="stylesheet" href="http://dimsemenov.com/plugins/magnific-popup/dist/magnific-popup.css">

<!-- meny -->
<script src="http://lab.hakim.se/meny/js/meny.min.js"></script>

<script>
/* run scripts when document is ready */
$(function() {
  "use strict";

  /* type of toc navigation */
  var nav = "onscreen";

  /* size of thumbnails */
  var thumbsize = "span3";

  var show_code = true;

  /* included languages */
  var languages = [];

  /* Using render_html, so add in code block */
  $('pre.knitr').each(function(){
    $(this).removeClass('knitr');
    if($(this).find('code').length < 1){
      $(this).wrapInner('<code class=' + $(this).attr('class') + '></code>');
    }
  });

  /* Add div wrapping class to code blocks without them */
  $('pre code').each(function(){

    var block_type, code_type;
    /* output block */
    if($(this).hasClass('')){
      block_type = "output";
      code_type = "";
    }
    /* source code block */
    else{
      block_type = "source";
      code_type = $(this).attr('class');
    }
    /* no wrapping div, not using render_html(), so add to wrap */
    if($(this).closest('div').length < 1){
      $(this).parent().wrap('<div class="' + [block_type, code_type].join(" ") + '"></div>');
    }
    /* just add code type to the parent div */
    else{
      $(this).closest('div').addClass(code_type);
    }
  });

  /* style tables, set them as output*/
  $('table').addClass('table table-striped table-bordered table-hover table-condensed')
    .wrap('<div class="output" style="overflow: auto"/>');

  /* find all code or output blocks which have a class and add toggle */
  $('div.source, div.output').each(function() {
    var button = $('<button class="btn-mini btn-link btn toggle" data-toggle="button">+/- </button>');

    /* code block */
    if($(this).hasClass('source')){
      var code_block = $(this).find('code');
      var lang_type = code_block.attr('class');
      button.text(button.text() + lang_type + ' Code');
      button.addClass('source ' + lang_type);
      languages[lang_type]=0;
      code_block.each(function(i, e) {
        hljs.highlightBlock(e);
      });
    }

    /* output block */
    else {
      button.text(button.text() + 'Output');
      button.addClass('output active');
    }
    $(this).before(button);
  });

  /* onclick toggle next code block */
  $('.toggle').click(function() {
    $(this).button('toggle');
    $(this).next('div').slideToggle();
    return false;
  });

  /* give images a lightbox and thumbnail classes to allow lightbox and thumbnails TODO: make gallery if graphs are grouped */
  $('p').each(function(){
    $(this).find('img').unwrap().wrapAll('<div class="rimage default"></div>');
  });
  $('div.rimage').each(function(){
    $(this).addClass("row-fluid thumbnails");
    $(this).children('img').wrap('<a href="#" class="mfp-image ' + thumbsize + ' thumbnail"></a></li>');
  });

  /* Magnific Popup */
  $(".thumbnail").each(function(){
    $(this).magnificPopup({
      disableOn: 768,
      closeOnContentClick: true,

      type: 'image',
      items: {
        src: $(this).find('img').attr('src'),
      }
    });
  });

  /* add bootstrap classes */
  $('body').wrapInner('<div class="container-fluid"><div class="row-fluid"><div class="contents">');

  var create_language_links = function(){
    var text='';
    var language;
    for(language in languages){
      if(languages.hasOwnProperty(language)){
        text += '<li><button style="width: 100%;" class="toggle-global btn-link btn source ' + language + '" type="source.' + language + '">' + language + '</button></li>\n';
      }
    }
    return text;
  }

  /* add navbar */
  $('.container-fluid').append(
    '<div id="bottom-navbar" class="navbar-fixed-bottom navbar">\
      <div class="navbar-inner">\
        <div class="pull-right">\
          <span class="navbar-text">Toggle</span>\
          <div class="btn-group dropup" data-toggle="button-checkbox">\
            <button type="source" class="source toggle-global btn">Code</button>\
            <button class="btn dropdown-toggle" data-toggle="dropdown">\
              <span class="caret"></span>\
            </button>\
            <ul class="dropdown-menu pull-right">'
              + create_language_links() +
            '</div>\
            <button type="output" class="output toggle-global btn active">Output</button>\
            <button type="thumbnails" class="toggle-global btn active">Plots</button>\
          </div>\
        </div>\
      </div>\
    </div>'
  );

  /* global toggles FIXME explicitly toggle all on/off using global variables */
  $('.toggle-global').click(function(){
    var type = $(this).attr('type');
    $('.' + type).button('toggle');
    $('div.' + type).slideToggle();
    return false;
  });

  /* if using render_html() hook, make functions links to custom R search */
  /*search in ggplot documentation or inside-r.org */
  $("span.functioncall").replaceWith(function(){
    return '<a target="_blank" href="http://www.google.com/search?sourceid=navclient&gfns=1&\
      q=site:docs.ggplot2.org/current OR site:inside-r.org ' +
    $(this).text() + '">' + $(this).text()+'</a>'
  });

  /* add footer */
  $('body').wrapInner('<div id="wrap" />');
  $('#wrap').append('<div id="push" />');
  var p = $('p:contains("Author:")');
  var last_p = p.filter(':last');
  p.detach();
  last_p.addClass('muted').attr('id','credit');
  last_p.append('<p>styled with <a href="https://github.com/jimhester/knitrBootstrap">knitrBootstrap</a></p>');
  last_p.appendTo("body");
  last_p.wrap('<div id="footer">');

  $('.container-fluid > .row-fluid').prepend('<div id="toc" class="well"/></div>');

  if(nav == 'offscreen'){
    $('#toc').wrap('<div class="meny">');
    $('.contents').addClass('span12').wrapInner('<div class="offset2 span8">');
    $('.meny').after('<div class="meny-arrow">');

    var meny = Meny.create({
        menuElement: document.querySelector( '.meny' ),
        contentsElement: document.querySelector( '.contents' ),
        position: 'left',
        width: 260
    });
  }
  else {
    $('#toc').css({ "padding-bottom": "36000px", "margin-bottom": "-36000px"}).addClass('span3');
    $('.contents').addClass('offset3 span8');
  }

  /* table of contents */
  $('#toc').tocify({extendPage: false});

  /* toggle code blocks hidden by default */
  if(show_code){
    /* toggle source bottons pressed */
    $('.source').filter(":button").addClass('active');
  }
  else {
    /* hide code blocks */
    $('div.source').toggle();
  }

  /* remove paragraphs with no content */
  $('p:empty').remove();

});

</script>
<style>
/* Knitr_bootstrap styles */
#wrap .container-fluid {
  padding: 0;
  overflow: hidden;
}
.toggle{
  text-transform: capitalize;
}

.toggle-global{
  text-transform: capitalize;
}

/*fix for boostrap#3494*/
.row-fluid.thumbnails .span5.thumbnail:nth-child(6n+1) { margin-left: 0px; }
.row-fluid.thumbnails .span5.thumbnail:nth-child(4n+1) { margin-left: 0px; }
.row-fluid.thumbnails .span5.thumbnail:nth-child(2n+1) { margin-left: 0px; }

/* Sticky footer styles */
* {
  margin:0;
}
html,
body {
    height: 100%;
    padding:0 !important;
    /* The html and body elements cannot have any padding or margin. */
    /*overflow-x: hidden;*/
}

/* Wrapper for page content to push down footer */
#wrap {
    min-height: 100%;
    height: auto !important;
    height: 100%;
    /* Negative indent footer by it's height */
    margin: 0 auto -120px;
}

/* Set the fixed height of the footer here */
#push,
#footer {
    height: 120px;
}

#footer {
  text-align: center;
}

/* Tocify */

#toc {
  border-radius: 0px;
  height:100%;
  padding: 9px;
  margin-right: -10px;
  position: fixed;
  width: 240px;
}
/* Top level subheader elements.  These are the first nested items underneath a header element. */
.header li {
  font-size: 20px;
}

/* Makes the font smaller for all subheader elements. */
.sub-header li {
    font-size: 12px;
}

.meny {
  height: 100%;
}

.meny-left.row-fluid {
  margin-left: 0%;
}


.meny-arrow {
  position: absolute;
  z-index: 10;

  border: 10px solid transparent;

  -webkit-transition: opacity 0.4s ease 0.4s; 
     -moz-transition: opacity 0.4s ease 0.4s; 
      -ms-transition: opacity 0.4s ease 0.4s; 
       -o-transition: opacity 0.4s ease 0.4s; 
          transition: opacity 0.4s ease 0.4s;
}
  .meny-left .meny-arrow {
    left: 14px;
    top: 50%;
    margin-top: -16px;
    border-left: 16px solid #AAA;
  }
  .meny-active .meny-arrow {
    opacity: 0;

    -webkit-transition: opacity 0.2s ease; 
       -moz-transition: opacity 0.2s ease; 
        -ms-transition: opacity 0.2s ease; 
         -o-transition: opacity 0.2s ease; 
            transition: opacity 0.2s ease;
  }

.row-fluid > div.contents.span12 {
  margin-left: 0;
}
.navbar-inner > .pull-right {
  padding-right: 20px;
}

.mfp-figure:after {
  background: white;
}

</style>

 

</head>

<body>
<h1>An Introduction to the <code>prospectr</code> package</h1>

<p><em>Antoine Stevens &amp; Leonardo Ramirez-Lopez</em></p>

<p>Visible and Near Infrared diffuse reflectance (vis--NIR) spectroscopy is a high--troughput, non--destructive and cheap sensing method that has a range of applications in agricultural, medical, food and environmental science. A number of R packages of interest for the spectroscopist is already available for processing and analysis of spectroscopic data (Table 1). The CRAN task views <a href="http://cran.r-project.org/web/views/Multivariate.html">Multivariate Statistics</a>, <a href="http://cran.r-project.org/web/views/MachineLearning.html">Machine Learning</a>, <a href="http://cran.r-project.org/web/views/ChemPhys.html">Chemometrics and Computational Physics</a>. The interested reader can also have a look at the special issue <a href="http://ww.colin-baxter.com/academic/bib/downloads/mullen07.pdf">&quot;Spectroscopy and Chemometrics in R&quot;</a> of the Journal of Statistical Software (<span class="showtooltip" title="Mullen KM and Stokkum IHv (2007). 'An Introduction to the Special Volume Spectroscopy and Chemometrics in R.' Journal of Statistical Software, 18(1), pp. 1-5. ."><a href="http://ww.colin-baxter.com/academic/bib/downloads/mullen07.pdf">Mullen &amp; Stokkum, 2007</a></span>).</p>

<table><thead>
<tr>
<th>Package Name</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>chemometrics</code></td>
<td>functions and scripts for chemometrics</td>
</tr>
<tr>
<td><code>ChemometricsWithR</code></td>
<td>functions and scripts for chemometrics</td>
</tr>
<tr>
<td><code>ChemoSpec</code></td>
<td>misc functions for exploratory analysis in Spectroscopy</td>
</tr>
<tr>
<td><code>hyperSpec</code></td>
<td>processing and visualisation of spectra</td>
</tr>
<tr>
<td><code>cluster</code></td>
<td>cluster analysis and visualisation</td>
</tr>
<tr>
<td><code>mvoutlier</code></td>
<td>outlier detection in the multivariate space</td>
</tr>
<tr>
<td><code>pls</code></td>
<td>partial least square regression</td>
</tr>
<tr>
<td><code>signal</code></td>
<td>signal filtering</td>
</tr>
<tr>
<td><code>soil.spec</code></td>
<td>some functions related to soil spectroscopy</td>
</tr>
<tr>
<td><code>caret</code></td>
<td>training classification and regression models</td>
</tr>
</tbody></table>

<p>Table 1: Non-exhaustive list of R package useful for vis--NIR spectroscopic analysis</p>

<p>The prospect package gathers algorithms commonly--used in spectroscopy for pre--treating spectra and select calibration samples. Some of the algorithms are already available in other package, like the Savitzky--Golay algorithm (<span class="showtooltip" title="Savitzky A and Golay MJE (1964). 'Smoothing and differentiation of data by simplified least squares procedures.' Anal. Chem., 36(8), pp. 1627-1639. ISSN 0003-2700."><a href="http://dx.doi.org/10.1021/ac60214a047">Savitzky &amp; Golay, 1964</a></span>) but our functions works indifferently on <code>vector</code>, <code>data.frame</code> or  <code>matrix</code> input and are optimized for speed using the <a href="http://cran.r-project.org/web/packages/Rcpp/index.html">Rcpp</a> and <a href="http://cran.r-project.org/web/packages/RcppArmadillo/index.html">RcppArmadillo</a> packages. </p>

<h1>Signal Processing</h1>

<p>The aim of signal pre--treatment is to improve data quality before modeling and remove physical information from the spectra. Applying a pre--treatment can increase the repeatability/reproducibility of the method, model robustness and accuracy, although there are no guarantees this will actually work...The pre--processing functions that are currently available in the package are listed in Table 2.</p>

<table><thead>
<tr>
<th>Function Name</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>movav</code></td>
<td>simple moving (or running) average filter</td>
</tr>
<tr>
<td><code>savitzkyGolay</code></td>
<td>Savitzky--Golay smoothing and derivative</td>
</tr>
<tr>
<td><code>gapDer</code></td>
<td>gap--segment derivative</td>
</tr>
<tr>
<td><code>continuumRemoval</code></td>
<td>compute continuum--removed values</td>
</tr>
<tr>
<td><code>detrend</code></td>
<td>detrend normalization</td>
</tr>
<tr>
<td><code>standardNormalVariate</code></td>
<td>Standard Normal Variate (SNV) transformation</td>
</tr>
<tr>
<td><code>binning</code></td>
<td>average a signal in column bins</td>
</tr>
<tr>
<td><code>resample</code></td>
<td>resample a signal to new band positions</td>
</tr>
<tr>
<td><code>resample2</code></td>
<td>resample a signal using new FWHM values</td>
</tr>
<tr>
<td><code>blockScale</code></td>
<td>block scaling</td>
</tr>
<tr>
<td><code>blockNorm</code></td>
<td>sum of squares block weighting</td>
</tr>
</tbody></table>

<p>Table 2: List of pre--processing functions</p>

<p>We show below how they can be used, using the NIRsoil dataset included in the package (<span class="showtooltip" title="Pierna JAF and Dardenne P (2008). 'Soil parameter quantification by NIRS as a Chemometric challenge at Chimiometrie 2006.' Chemometrics and Intelligent Laboratory Systems, 91(1), pp. 94-98. ."><a href="http://www.sciencedirect.com/science/article/pii/S0169743907001190">Pierna &amp; Dardenne, 2008</a></span>). Observations should be arranged row--wise.</p>

<pre><code class="r">library(prospect)
data(NIRsoil)
# NIRsoil is a data.frame with 825 obs and 5 variables: Nt (Total
# Nitrogen), Ciso (Carbon), CEC (Cation Exchange Capacity), train (vector
# of 0,1 indicating training (1) and validation (0) samples), spc
# (spectral matrix)
str(NIRsoil)
</code></pre>

<pre><code>## &#39;data.frame&#39;:    825 obs. of  5 variables:
##  $ Nt   : num  0.3 0.69 0.71 0.85 NA ...
##  $ Ciso : num  0.22 NA NA NA 0.9 NA NA 0.6 NA 1.28 ...
##  $ CEC  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ train: num  1 1 1 1 1 1 1 1 1 1 ...
##  $ spc  : num [1:825, 1:700] 0.339 0.308 0.328 0.364 0.237 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr  &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr  &quot;1100&quot; &quot;1102&quot; &quot;1104&quot; &quot;1106&quot; ...
</code></pre>

<h2>Noise removal</h2>

<p>Noise represents random fluctuations around the signal that can originate from the instrument or environmental laboratory conditions. The simplest solution to remove noise is to perform \(n\) repetition of the measurements, and the average individual spectra. The noise will decrease with a factor \(\sqrt{n}\). When this is not possible, or if residual noise is still present in the data, the noise can be removed mathematically. </p>

<h3>Moving average or runnnig mean</h3>

<p>A moving average filter is a column--wise operation which average contiguous wavelengths within a given window size. </p>

<pre><code class="r">noisy &lt;- NIRsoil$spc + rnorm(length(NIRsoil$spc), 0, 0.001)  # adding some noise
# Plot the first spectrum
plot(as.numeric(colnames(NIRsoil$spc)), noisy[1, ], type = &quot;l&quot;, xlab = &quot;Wavelength&quot;, 
    ylab = &quot;Absorbance&quot;)
X &lt;- movav(noisy, w = 11)  # window size of 11 bands
# Note that the 5 first and last bands are lost in the process
lines(as.numeric(colnames(X)), X[1, ], col = &quot;red&quot;)
legend(&quot;topleft&quot;, legend = c(&quot;raw&quot;, &quot;moving average&quot;), lty = c(1, 1), col = 1:2)
</code></pre>

<p><img src="figure/movin.png" alt="Effect of a moving average with window size of 10 bands on a raw spectrum"/> </p>

<h3>Binning</h3>

<p>After averaging, the spectrum can be further resampled (binning).</p>

<pre><code class="r"># We keep here one 1 out every 10 data points
X.bin &lt;- binning(X, bin.size = 10)
# We reduce the spectral matrix to 50 (equally-spaced) data points
X.bin2 &lt;- binning(X, bins = 50)
# Plot the first spectrum
plot(as.numeric(colnames(X)), X[1, ], type = &quot;l&quot;, xlab = &quot;Wavelength&quot;, ylab = &quot;Absorbance&quot;)
# new data points
points(as.numeric(colnames(X.bin)), X.bin[1, ], pch = 2)
points(as.numeric(colnames(X.bin2)), X.bin2[1, ], pch = 1, col = 2)
legend(&quot;topleft&quot;, legend = c(&quot;bin.size = 10&quot;, &quot;bins = 50&quot;), pch = 2:1, col = 2:1)
</code></pre>

<p><img src="figure/binning.png" alt="Binning a spectrum"/> </p>

<h3>Savitzky-Golay filtering</h3>

<p>Savitzky-Golay filtering (<span class="showtooltip" title="Savitzky A and Golay MJE (1964). 'Smoothing and differentiation of data by simplified least squares procedures.' Anal. Chem., 36(8), pp. 1627-1639. ISSN 0003-2700."><a href="http://dx.doi.org/10.1021/ac60214a047">Savitzky &amp; Golay, 1964</a></span>) is a very common preprocessing technique. It fits a local polynomial regression on the signal and requires <strong>equidistant</strong> bandwidth. Mathematically, it operates simply as a weighted sum of neighbouring values:</p>

<p>\[ x_j\ast = \frac{1}{N}\sum_{h=-k}^{k}{c_hx_{j+h}}\]</p>

<p>where \(x_j\ast\) is the new value, \(N\) is a normalizing coefficient, \(k\) is the number of neighbour values at each side of \(j\) and \(c_h\) are pre--computed coefficients, that depends on the chosen polynomial order and degree (smoothing, first and second derivative).</p>

<pre><code class="r"># p = polynomial order w = window size (must be odd) m = m-th derivative
# (0 = smoothing) The function accepts vectors, data.frames or matrices.
# For a matrix input, observations should be arranged row-wise
sg.vec &lt;- savitzkyGolay(NIRsoil$spc[1, ], p = 3, w = 11, m = 0)
sg &lt;- savitzkyGolay(NIRsoil$spc, p = 3, w = 11, m = 0)
# note that bands at the edges of the spectral matrix are lost !
dim(NIRsoil$spc)
</code></pre>

<pre><code>## [1] 825 700
</code></pre>

<pre><code class="r">dim(sg)
</code></pre>

<pre><code>## [1] 825 690
</code></pre>

<h2>Derivatives</h2>

<p>Taking (numerical) derivatives of the spectra can remove both additive and multiplicative effects in the spectra and have other consequences as well (Table 3).</p>

<p>Advantage                            Drawback</p>

<hr/>

<p>Reduce of baseline offset            Risk of overfitting the calibration model
  Can resolve absorption overlapping   Increase noise, smoothing required
  Compensates for instrumental drift   Increase uncertainty in model coefficients<br/>
  Enhances small spectral absorptions  Complicate spectral interpretation
  Often increase predictive accuracy   Remove the baseline ! 
  for complex datasets</p>

<p>Table 3: Pro&#39;s and con&#39;s of using derivative spectra.</p>

<p>First and second derivatives of a spectrum can be computed with the finite difference method (difference between to subsequent data points), provided that the band width is constant: </p>

<p>\[ x_i' = x_i - x_{i-1}\]</p>

<p>\[ x_i'' = x_{i-1} - 2 \cdot x_i + x_{i+1}\]</p>

<p>In R, this can be simply achieved with the <code>diff</code> function in <code>base</code>: </p>

<pre><code class="r"># X = wavelength Y = spectral matrix n = order
d1 &lt;- t(diff(t(NIRsoil$spc), differences = 1))  # first derivative
d2 &lt;- t(diff(t(NIRsoil$spc), differences = 2))  # second derivative
plot(as.numeric(colnames(d1)), d1[1, ], type = &quot;l&quot;, xlab = &quot;Wavelength&quot;, ylab = &quot;&quot;)
lines(as.numeric(colnames(d2)), d2[1, ], col = &quot;red&quot;)
legend(&quot;topleft&quot;, legend = c(&quot;1st der&quot;, &quot;2nd der&quot;), lty = c(1, 1), col = 1:2)
</code></pre>

<p><img src="figure/d1.png" alt="Effect of first derivative and second derivative"/> </p>

<p>One can see that derivatives tend to increase noise. One can use gap derivatives or the Savitzky-Golay algorithm to solve this. The gap derivative is computed simply as:</p>

<p>\[ x_i' = x_{i+k} - x_{i-k}\]</p>

<p>\[ x_i'' = x_{i-k} - 2 \cdot x_i + x_{i+k}\]</p>

<p>where \(k\) is the gap size. Again, this can be easily achieved in R using the <code>lag</code> argument of the <code>diff</code> function</p>

<pre><code class="r"># first derivative with a gap of 10 bands
gd1 &lt;- t(diff(t(NIRsoil$spc), differences = 1, lag = 10))
</code></pre>

<p>For more flexibility and control over the degree of smoothing, one could however use the Savitzky-Golay (<code>savitzkyGolay</code>) and Gap-segment derivative (<code>gapDer</code>) algorithms. The Gap-segment algorithms performs first a smoothing under a given segment size, followed by . Here is an exemple of the use of the <code>gapDer</code> function.</p>

<pre><code class="r"># m = order of the derivative w = window size ( = {2 * gap size} + 1) s =
# segment size first derivative with a gap of 10 bands
gsd1 &lt;- gapDer(X = NIRsoil$spc, m = 1, w = 11, s = 10)
plot(as.numeric(colnames(d1)), d1[1, ], type = &quot;l&quot;, xlab = &quot;Wavelength&quot;, ylab = &quot;&quot;)
lines(as.numeric(colnames(gsd1)), gsd1[1, ], col = &quot;red&quot;)
legend(&quot;topleft&quot;, legend = c(&quot;1st der&quot;, &quot;gap-segment 1st der&quot;), lty = c(1, 1), 
    col = 1:2)
</code></pre>

<p><img src="figure/gapseg.png" alt="Effect of 1st-order gap-segment derivative "/> </p>

<h2>Scatter corrections</h2>

<p>Undesired spectral variations due to light <em>scatter</em> effects and variations in effective <em>path length</em>  can be removed using scatter corrections.</p>

<h3>Standard Normal Variate (SNV)</h3>

<p><em>Standard Normal Variate</em> (SNV) is another simple way for normalizing spectra that intends to correct for light <em>scatter</em>. It operates row--wise:</p>

<p>\[ SNV_i = \frac{x_i - \bar{x_i}}{s_i}\]</p>

<pre><code class="r">snv &lt;- standardNormalVariate(X = NIRsoil$spc)
</code></pre>

<p>According to Fearn (<span class="showtooltip" title="Fearn T (2008). 'The interaction between standard normal variate and derivatives.' NIR news, 19(7), pp. 16. ISSN 0960-3360."><a href="http://dx.doi.org/10.1255/nirn.1098">Fearn, 2008</a></span>), it is better to perform SNV transformation after filtering (by e.g. Savitzky--Golay) than the reverse</p>

<h3>SNV-Detrend</h3>

<p>The <em>SNV-Detrend</em> (<span class="showtooltip" title="Barnes R, Dhanoa M and Lister S (1989). 'Standard normal variate transformation and de-trending of near-infrared diffuse reflectance spectra.' Applied spectroscopy, 43(5), pp. 772-777."><a href="">Barnes et al. 1989</a></span>) further accounts for wavelength-dependent scattering effects (variation in curvilinearity between the spectra). After a <em>SNV</em> transformation, a 2\(^{nd}\)--order polynomial is fit to the spectrum and subtracted from it.</p>

<pre><code class="r"># X = input spectral matrix wav = band centers
dt &lt;- detrend(X = NIRsoil$spc, wav = as.numeric(colnames(NIRsoil$spc)))
plot(NIRsoil$spc[1, ], type = &quot;l&quot;, xlab = &quot;Band number&quot;, ylab = &quot;&quot;)
par(new = T)
plot(dt[1, ], xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;, col = &quot;red&quot;, type = &quot;l&quot;)
axis(4, col = &quot;red&quot;)
legend(&quot;topleft&quot;, legend = c(&quot;raw&quot;, &quot;detrend signal&quot;), lty = c(1, 1), col = 1:2)
</code></pre>

<p><img src="figure/detrend.png" alt="Effect of SNV-Detrend on raw spectra"/> </p>

<pre><code class="r">par(new = F)
</code></pre>

<h2>Centering and scaling</h2>

<p>Centering and scaling tranforms a given matrix to a matrix with columns with zero mean (<em>centering</em>), unit variance (<em>scaling</em>) or both (<em>auto-scaling</em>):</p>

<p>\[ Xc_{ij} = X_{ij}  - \bar{X}_{j} \]</p>

<p>\[ Xs_{ij} = \frac{X_{ij}  - \bar{X}_{j}}{s_{j}} \]</p>

<p>where \(Xc\) and \(Xs\) are the mean centered and auto-scaled matrices, \(X\) is the input matrix, \(\bar{X}_{j}\) and \(s_{j}\) are the mean and standard deviation of variable \(j\).</p>

<p>In R, these operations are simply obtained with the <code>scale</code> function. Other types of scaling can be considered.  Spectroscopic models can often be improved by using ancillary data (e.g. temperature, ...) (<span class="showtooltip" title="Fearn T (2010). 'Combining other predictors with NIR spectra.' NIR news, 21(2), pp. 13. ISSN 0960-3360."><a href="http://dx.doi.org/10.1255/nirn.1175">Fearn, 2010</a></span>). Due to the nature of spectral data (multivariate), other data would have great chance to be dominated by the spectral matrix and have no chance to contribute significantly to the model due to purely numerical reasons (<span class="showtooltip" title="Eriksson L, Johansson E, Kettaneh N, Trygg J, Wikstrom C and Wold S (2006). Multi- and Megavariate Data Analysis. MKS Umetrics AB. ISBN 9789197373029."><a href="">Eriksson et al. 2006</a></span>). One can use <em>block scaling</em> to overcome this limitation. It basically uses different weights for different block of variables. With <em>soft block scaling</em>, each block is scaled (ie each column divided by a factor) such that the sum of their variance is equal to the square root of the number of variables in the block. With <em>hard block scaling</em>, each block is scaled such that the sum of their variance is equal to 1.</p>

<pre><code class="r"># X = spectral matrix type = &#39;soft&#39; or &#39;hard&#39; The ouptut is a list with
# the scaled matrix (Xscaled) and the divisor (f)
bs &lt;- blockScale(X = NIRsoil$spc, type = &quot;hard&quot;)$Xscaled
sum(apply(bs, 2, var))  # this works!
</code></pre>

<pre><code>## [1] 1
</code></pre>

<p>The problem with <em>block scaling</em> is that it down--scale all the block variables to the same variance. Since sometimes this is not advised, one can alternatively use <em>sum of squares block weighting</em> . The spectral matrix is multiplied by a factor to achieve a pre--determined sum of square: </p>

<pre><code class="r"># X = spectral matrix targetnorm = desired norm for X
bn &lt;- blockNorm(X = NIRsoil$spc, targetnorm = 1)$Xscaled
sum(bn^2)  # this works!
</code></pre>

<pre><code>## [1] 1
</code></pre>

<h2>Other transformations</h2>

<h3>Continuum removal</h3>

<p>The continuum removal technique was introduced by (<span class="showtooltip" title="Clark RN and Roush TL (1984). 'Reflectance Spectroscopy: Quantitative Analysis Techniques for Remote Sensing Applications.' Journal of Geophysical Research, 89(B7), pp. PP. 6329-6340. ."><a href="http://dx.doi.org/198410.1029/JB089iB07p06329">Clark &amp; Roush, 1984</a></span>) as an effective method to highlight absorption features of minerals. It can be viewed as an albedo normalization technique. This technique is based on the computation of the continuum (or envelope) of a given spectrum. The continuum-removed spectrum of a given spectrum is computed as follows:</p>

<ol>
<li><p>The local reflectance spectrum maxima points (in the case of absorbance, local minima points) are identified.   </p></li>
<li><p>Then, these points are connected by linear interpolation to form the continuum. </p></li>
<li><p>The continuum-removed spectrum is given by \(\phi_{i} = \frac{x_{i}}{c_{i}};  i=\left \{ 1,..., p\right\}\), where \(x_{i}\) and \(c_{i}\) are the original and the continuum reflectance (or absorbance) values respectively at the \(i\)<sup>th</sup> wavelength of a set of \(p\) wavelengths, and \(\phi_{i}\) is the final reflectance (or absorbance) value after continuum removal.</p></li>
</ol>

<p>The <code>continuumRemoval</code> function allows to compute the continuum-removed values of either reflectance or absorbance spectra. </p>

<pre><code class="r"># type of data: &#39;R&#39; for reflectance (default), &#39;A&#39; for absorbance
cr &lt;- continuumRemoval(X = NIRsoil$spc, type = &quot;A&quot;)
# plot of the 10 first abs spectra
matplot(as.numeric(colnames(NIRsoil$spc)), t(NIRsoil$spc[1:10, ]), type = &quot;l&quot;, 
    ylim = c(0, 0.6), xlab = &quot;Wavelength /nm&quot;, ylab = &quot;Absorbance&quot;)
matlines(as.numeric(colnames(NIRsoil$spc)), t(cr[1:10, ]))
</code></pre>

<p><img src="figure/cr.png" alt="Absorbance and continuum-removed absorbance spectra"/> </p>

<h3>Resampling</h3>

<p>To match the response of one instrument with another, a signal can be resampled to new band positions by simple interpolation (<code>resample</code>) or using full width half maximum (FWHM) values (<code>resample2</code>). </p>

<h1>Calibration sampling algorithms</h1>

<p>Calibration models are usually developed on a <em>representative</em> portion of the data (training set) and validated on the remaining set of samples (test/validation set). There are several solutions for selecting samples, e.g.:   </p>

<ul>
<li>random selection (see e.g. <code>sample</code> function in <code>base</code>)</li>
<li>stratified random sampling on percentiles of the response \(y\) (see e.g. <code>createDataPartion</code> in the <a href="http://cran.r-project.org/web/packages/caret/index.html"><code>caret</code></a> package)</li>
<li>use the spectral data. </li>
</ul>

<p>For selecting representative samples, the <code>prospect</code> package provides functions that use the third solution. The following functions are available: <code>kenStone</code> (<span class="showtooltip" title="Kennard RW and Stone LA (1969). 'Computer aided design of experiments.' Technometrics, 11(1), pp. 137-148. ISSN 0040-1706."><a href="http://dx.doi.org/10.2307/1266770">Kennard &amp; Stone, 1969</a></span>), <code>duplex</code> (<span class="showtooltip" title="Snee RD (1977). 'Validation of regression models: methods and examples.' Technometrics, 19(4), pp. 415-428. ."><a href="http://amstat.tandfonline.com/doi/abs/10.1080/00401706.1977.10489581">Snee, 1977</a></span>), <code>puchwein</code> (<span class="showtooltip" title="Puchwein G (1988). 'Selection of calibration samples for near-infrared spectrometry by factor analysis of spectra.' Analytical Chemistry, 60(6), pp. 569-573. ."><a href="http://pubs.acs.org/doi/abs/10.1021/ac00157a015">Puchwein, 1988</a></span>), <code>shenkWest</code> (<span class="showtooltip" title="Shenk JS and Westerhaus MO (1991). 'Population Definition, Sample Selection, and Calibration Procedures for Near Infrared Reflectance Spectroscopy.' Crop Science, 31(2), pp. 469-474. ISSN 0011-183X."><a href="http://dx.doi.org/10.2135/cropsci1991.0011183X003100020049x">Shenk &amp; Westerhaus, 1991</a></span>), <code>naes</code> (<span class="showtooltip" title="Naes T, Isaksson T, Fearn T and Davies T (2002). A user friendly guide to multivariate calibration and classification. NIR Publications, Chichester, United Kingdom. ISBN 0-9528666-2-5."><a href="">Naes et al. 2002</a></span>), <code>honigs</code> (<span class="showtooltip" title="Honigs DE, Hieftje GM, Mark HL and Hirschfeld TB (1985). 'Unique-sample selection via near-infrared spectral subtraction.' Analytical Chemistry, 57(12), pp. 2299-2303. ISSN 0003-2700."><a href="http://dx.doi.org/10.1021/ac00289a029">Honigs et al. 1985</a></span>).</p>

<h3>Kennard-Stone sampling (<code>kenStone</code>)</h3>

<p>To sample a subset of \(n\)  samples \(X_{tr} = \left \{ {x_{tr}}_{j} \right \}_{j=1}^{n}\), from a given set of \(N\) samples \(X = \left \{ x_i \right \}_{i=1}^{N}\) (note that \(N>n\)) the Kennard-Stone (CADEX) sampling  algorithm consists in \cite{kennard1969}: </p>

<ol>
<li><p>Find in \(X\) the samples \({x_{tr}}_1\) and  \({x_{tr}}_2\) that are the farthest apart from each other,           allocate them in \(X_{tr}\)  and remove them from \(X\).   </p></li>
<li><p>Find in \(X\) the sample \({x_{tr}}_3\) with the maximum dissimilarity to \(X_{tr}\). Allocate \({x_{tr}}_3\) in \(X_{tr}\)  and then remove it from \(X\). The dissimilarity between \(X_{tr}\)  and each \(x_i\)  is given by the minimum distance of any sample allocated in \(X_{tr}\)  to each \(x_i\). In other words, the selected sample is one of the nearest neighbours of the points already selected which is characterized by the maximum distance to the other points already selected.   </p></li>
<li><p>Repeat the step 2 n-3 times in order to select the remaining samples (\({x_{tr}}_4,..., {x_{tr}}_n\)).   </p></li>
</ol>

<p>The Kennard--Stone algorithm allows to create a calibration set that has a flat distribution over the spectral space. The metric used to compute the distance between points can be either the Euclidean distance or the Mahalanobis distance. 
Let&#39;s see some examples...</p>

<pre><code class="r"># Create a dataset for illustrating how the calibration sampling 
# algorithms work
X &lt;- data.frame(x1 = rnorm(1000), x2 = rnorm(1000))
plot(X) 
# kenStone produces a list with row index of the points selected for calibration
ken &lt;- kenStone(X,k=40) 
points(X[ken$model,],col=2,pch=19,cex=1.4) # plot selected points
</code></pre>

<p><img src="figure/ken.png" title="Selection of 40 calibration samples with the Kennard-Stone algorithm" alt="Selection of 40 calibration samples with the Kennard-Stone algorithm" width="10cm" height="10cm" /></p>

<pre><code class="r">
# Test with the NIRsoil dataset
# one can use the mahalanobis distance
# The mahalanobis distance is computed by taking the Euclidean distance 
# in the normalized principal component score space 
# (see Maesschalck et al. 2000, Chemo. Int. Lab. Syst. 50, 1-18)
# If the &#39;pc&#39; argument is set, the Mahalanobis distance will be used
# The &#39;pc&#39; argument is the number of pc&#39;s retained in the computation of the distance
# if &#39;pc&#39; &lt; 1, then it corresponds to a treshold in terms of explained variance
ken_mahal &lt;- kenStone(X = NIRsoil$spc, k = 20, pc= .999)
# The pc components in the output list stores the pc scores
plot(ken_mahal$pc[,1],ken_mahal$pc[,2],xlab=&quot;PC1&quot;,ylab=&quot;PC2&quot;) 
# This is the selected points in the pc space
points(ken_mahal$pc[ken_mahal$model,1],ken_mahal$pc[ken_mahal$model,2],pch=19,col=2) 
</code></pre>

<p><img src="figure/ken2.png" title="Kennard-Stone sampling on the NIRsoil dataset" alt="Kennard-Stone sampling on the NIRsoil dataset" width="10cm" height="10cm" /></p>

<h3>DUPLEX (<code>duplex</code>)</h3>

<p>The Kennard--Stone algorithm selects <em>calibration</em> samples. Often, we need also to select a <em>validation</em> subset. The DUPLEX algorithm (<span class="showtooltip" title="Snee RD (1977). 'Validation of regression models: methods and examples.' Technometrics, 19(4), pp. 415-428. ."><a href="http://amstat.tandfonline.com/doi/abs/10.1080/00401706.1977.10489581">Snee, 1977</a></span>) is a modification of the Kennard-Stone which allows to select a <em>validation</em> set that have similar properties to the <em>calibration_set. DUPLEX, similarly to Kennard--Stone, begins by selecting pairs of points that are the farthest apart from each other, and then assigns points alternatively to the _calibration</em> and <em>validation</em> sets.</p>

<pre><code class="r">dup &lt;- duplex(X = X, k = 15)  # k is the number of selected samples
plot(X)
points(X[dup$model, 1], X[dup$model, 2], col = &quot;red&quot;, pch = 19)  # calibration samples
points(X[dup$test, 1], X[dup$test, 2], col = &quot;blue&quot;, pch = 17)  # validation samples
legend(&quot;topright&quot;, legend = c(&quot;calibration&quot;, &quot;validation&quot;), pch = c(19, 17), 
    col = c(&quot;red&quot;, &quot;blue&quot;))
</code></pre>

<p><img src="figure/duplex.png" alt="Selection of 15 calibration and validation samples with the DUPLEX algorithm"/> </p>

<h3>\(k\)-means sampling (<code>naes</code>)</h3>

<p>The \(k\)-means sampling simply uses \(k\)-means clustering algorithm. To sample a subset of \(n\)  samples \(X_{tr} = \left \{ {x_{tr}}_{j} \right \}_{j=1}^{n}\), from a given set of \(N\) samples \(X = \left \{ x_i \right \}_{i=1}^{N}\) (note that \(N>n\)) the algorithm works as follows:</p>

<ol>
<li><p>Perform a \(k\)-means clustering of \(X\) using \(n\) clusters.   </p></li>
<li><p>Extract the \(n\) centroids (\(c\), or prototypes). This can be also the sample that is the farthest away from the centre of the data, or a random selection. See the <code>method</code> argument in <code>naes</code> </p></li>
<li><p>Calculate the distance of each sample to each \(c\).  </p></li>
<li><p>For each \(c\) allocate in \(X_{tr}\) its closest sample found in \(X\).   </p></li>
</ol>

<pre><code class="r"># X = the input matrix k = number of calibration samples to be selected pc
# = if pc is specified, k-mean is performed in the pc space (here we will
# use only the two 1st pcs) iter.max = maximum number of iterations
# allowed for the k-means clustering.
kms &lt;- naes(X = NIRsoil$spc, k = 5, pc = 2, iter.max = 100)
# Plot the pcs scores and clusters
plot(kms$pc, col = kms$cluster)
# Add the selected points
points(kms$pc[kms$model, ], col = 6, pch = 19)
</code></pre>

<p><img src="figure/naes.png" alt="Selection of 5 samples by k-means sampling"/> </p>

<h3>SELECT algorithm (<code>shenkWest</code>)</h3>

<p>The SELECT algorithm (<span class="showtooltip" title="Shenk JS and Westerhaus MO (1991). 'Population Definition, Sample Selection, and Calibration Procedures for Near Infrared Reflectance Spectroscopy.' Crop Science, 31(2), pp. 469-474. ISSN 0011-183X."><a href="http://dx.doi.org/10.2135/cropsci1991.0011183X003100020049x">Shenk &amp; Westerhaus, 1991</a></span>) is an iterative procedure which selects the sample having the maximum number of neighbour samples within a given distance (<code>d.min</code> argument) and remove the neighbour samples of the selected sample from the list of points. The number of selected samples depends on the chosen treshold (default = 0.6). The distance metric is the Mahalanobis distance divided by the number of dimensions (number of pc components) used to compute the distance. Here is an example of how the <code>shenkWest</code> function might work:</p>

<pre><code class="r">shenk &lt;- shenkWest(X = NIRsoil$spc, d.min = 0.6, pc = 2)
plot(shenk$pc)
points(shenk$pc[shenk$model, ], col = 2, pch = 19)
</code></pre>

<p><img src="figure/shenk.png" alt="Selection of samples with the SELECT algorithm"/> </p>

<h3>Puchwein algorithm (<code>puchwein</code>)</h3>

<p>The Puchwein algorithm is yet another algorithm for calibration sampling (<span class="showtooltip" title="Puchwein G (1988). 'Selection of calibration samples for near-infrared spectrometry by factor analysis of spectra.' Analytical Chemistry, 60(6), pp. 569-573. ."><a href="http://pubs.acs.org/doi/abs/10.1021/ac00157a015">Puchwein, 1988</a></span>) that create a calibration set with a flat distribution. A nice feature of the algorithm is that it allows an objective selection of the number of required calibration samples with the help of plots. First the data is usually reduced through PCA and the most significant PCs are retained. Then the mahalanobis distance (\(H\)) to the center of the matrix is computed and samples are sorted decreasingly. The distances betwwen samples in the PC space are then computed.</p>

<ul>
<li>Here is a <code>pseudo-code</code> of the algorithm:</li>
</ul>

<pre><code>1. Definition of a limiting distance
2. Find the sample with $\max(H)$
3. Remove all the samples which are within the limiting distance away from the sample selected in step 2.
4. Go back in step 2 and find the sample with $\max(H)$ within the remaining samples
5. When there is no sample anymore, go back to step 1 and increase the limiting distance.
</code></pre>

<pre><code class="r">pu &lt;- puchwein(X = NIRsoil$spc, k = 0.2, pc = 2)
plot(pu$pc)
points(pu$pc[pu$model, ], col = 2, pch = 19)  # selected samples
</code></pre>

<p>The number of sample selected depends on the limiting distance. To help choosing the appropriate number of samples, two plots are used (<span class="showtooltip" title="Shetty N, Rinnan A and Gislum R (2012). 'Selection of representative calibration sample sets for near-infrared reflectance spectroscopy to predict nitrogen concentration in grasses.' Chemometrics and Intelligent Laboratory Systems, 111(1), pp. 59-65. ISSN 0169-7439."><a href="http://dx.doi.org/10.1016/j.chemolab.2011.11.013">Shetty et al. 2012</a></span>):</p>

<ul>
<li>a plot showing the number of samples that are removed in each loop and the total number of samples left</li>
<li>a plot showing the theoretical sum of leverages (each sample has the same leverage) together with the true sum of leverages. The optimal loop is the one for which the difference between the two measures of leverage is maximum.</li>
</ul>

<pre><code class="r">par(mfrow = c(2, 1))
plot(pu$leverage$removed, pu$leverage$diff, type = &quot;l&quot;, xlab = &quot;# samples removed&quot;, 
    ylab = &quot;Difference between th. and obs sum of leverages&quot;)
# This basically shows that the first loop is optimal
plot(pu$leverage$loop, nrow(NIRsoil) - pu$leverage$removed, xlab = &quot;# loops&quot;, 
    ylab = &quot;# samples kept&quot;, type = &quot;l&quot;)
par(mfrow = c(1, 1))
</code></pre>

<h3>Honigs (<code>honigs</code>)</h3>

<p>The Honigs algorithm selects samples based on the size of their absorption features (<span class="showtooltip" title="Honigs DE, Hieftje GM, Mark HL and Hirschfeld TB (1985). 'Unique-sample selection via near-infrared spectral subtraction.' Analytical Chemistry, 57(12), pp. 2299-2303. ISSN 0003-2700."><a href="http://dx.doi.org/10.1021/ac00289a029">Honigs et al. 1985</a></span>). It can works both on absorbance and continuum-removed spectra. The sample having the highest absorption feature is selected first. Then this absorption is substracted from other spectra and the algorithm iteratively select samples with the highest absorption (in absolute value) until the desired number of samples is reached. </p>

<pre><code class="r">ho &lt;- honigs(X = NIRsoil$spc, k = 10, type = &quot;A&quot;)
# plot calibration spectra
matplot(as.numeric(colnames(NIRsoil$spc)), t(NIRsoil$spc[ho$model, ]), type = &quot;l&quot;, 
    xlab = &quot;Wavelength&quot;, ylab = &quot;Absorbance&quot;)
# add bands used during the selection process
abline(v = as.numeric(colnames(NIRsoil$spc))[ho$bands], lty = 2)
</code></pre>

<p><img src="figure/honigs.png" alt="Spectra selected with the Honigs algorithm and bands used"/> </p>

<h1>Reference</h1>

<ul>
<li>R.J. Barnes, M.S. Dhanoa, S.J. Lister,   (1989) Standard normal variate transformation and de-trending of near-infrared diffuse reflectance spectra.  <em>Applied spectroscopy</em>  <strong>43</strong>  (5)   772-777</li>
<li>Roger Clark, Ted Roush,   (1984) Reflectance Spectroscopy: Quantitative Analysis Techniques for Remote Sensing Applications.  <em>Journal of Geophysical Research</em>  <strong>89</strong>  (B7)   PP. 6329-6340  <a href="http://dx.doi.org/198410.1029/JB089iB07p06329">198410.1029/JB089iB07p06329</a></li>
<li>Lennart Eriksson, Erik Johansson, Nouna Kettaneh, Johan Trygg, C. Wikstrom, Svante Wold,   (2006) Multi- and Megavariate Data Analysis.</li>
<li>Tom Fearn,   (2008) The interaction between standard normal variate and derivatives.  <em>{NIR} news</em>  <strong>19</strong>  (7)   16-NA  <a href="http://dx.doi.org/10.1255/nirn.1098">10.1255/nirn.1098</a></li>
<li>Tom Fearn,   (2010) Combining other predictors with {NIR} spectra.  <em>{NIR} news</em>  <strong>21</strong>  (2)   13-NA  <a href="http://dx.doi.org/10.1255/nirn.1175">10.1255/nirn.1175</a></li>
<li>J. Pierna, P. Dardenne,   (2008) Soil parameter quantification by {NIRS} as a Chemometric challenge at Chimiometrie 2006.  <em>Chemometrics and Intelligent Laboratory Systems</em>  <strong>91</strong>  (1)   94-98  <a href="http://www.sciencedirect.com/science/article/pii/S0169743907001190">http://www.sciencedirect.com/science/article/pii/S0169743907001190</a></li>
<li>D. Honigs, Gary Hieftje, H. Mark, T. Hirschfeld,   (1985) Unique-sample selection via near-infrared spectral subtraction.  <em>Analytical Chemistry</em>  <strong>57</strong>  (12)   2299-2303  <a href="http://dx.doi.org/10.1021/ac00289a029">10.1021/ac00289a029</a></li>
<li>R. Kennard, L. Stone,   (1969) Computer aided design of experiments.  <em>Technometrics</em>  <strong>11</strong>  (1)   137-148  <a href="http://dx.doi.org/10.2307/1266770">10.2307/1266770</a></li>
<li>Katharine Mullen, Ivo Stokkum,   (2007) An Introduction to the Special Volume Spectroscopy and Chemometrics in R.  <em>Journal of Statistical Software</em>  <strong>18</strong>  (1)   1-5  <a href="http://ww.colin-baxter.com/academic/bib/downloads/mullen07.pdf">http://ww.colin-baxter.com/academic/bib/downloads/mullen07.pdf</a></li>
<li>T. Naes, T. Isaksson, T. Fearn, T. Davies,   (2002) A user friendly guide to multivariate calibration and classification.</li>
<li>Gerd Puchwein,   (1988) Selection of calibration samples for near-infrared spectrometry by factor analysis of spectra.  <em>Analytical Chemistry</em>  <strong>60</strong>  (6)   569-573  <a href="http://pubs.acs.org/doi/abs/10.1021/ac00157a015">http://pubs.acs.org/doi/abs/10.1021/ac00157a015</a></li>
<li>Abraham. Savitzky, M. Golay,   (1964) Smoothing and differentiation of data by simplified least squares procedures..  <em>Anal. Chem.</em>  <strong>36</strong>  (8)   1627-1639  <a href="http://dx.doi.org/10.1021/ac60214a047">10.1021/ac60214a047</a></li>
<li>J. Shenk, M. Westerhaus,   (1991) Population Definition, Sample Selection, and Calibration Procedures for Near Infrared Reflectance Spectroscopy.  <em>Crop Science</em>  <strong>31</strong>  (2)   469-474  <a href="http://dx.doi.org/10.2135/cropsci1991.0011183X003100020049x">10.2135/cropsci1991.0011183X003100020049x</a></li>
<li>Nisha Shetty, Asmund Rinnan, Rene Gislum,   (2012) Selection of representative calibration sample sets for near-infrared reflectance spectroscopy to predict nitrogen concentration in grasses.  <em>Chemometrics and Intelligent Laboratory Systems</em>  <strong>111</strong>  (1)   59-65  <a href="http://dx.doi.org/10.1016/j.chemolab.2011.11.013">10.1016/j.chemolab.2011.11.013</a></li>
<li>R. Snee,   (1977) Validation of regression models: methods and examples.  <em>Technometrics</em>  <strong>19</strong>  (4)   415-428  <a href="http://amstat.tandfonline.com/doi/abs/10.1080/00401706.1977.10489581">http://amstat.tandfonline.com/doi/abs/10.1080/00401706.1977.10489581</a></li>
</ul>

<!---
knit("vignettes/prospectr-intro.Rmd","vignettes/prospectr-intro.md")
knit_bootstrap_md("vignettes/prospectr-intro.md",boot_style="flatly",code_style="github",nav_type="onscreen",show_code=T)
--->

</body>

</html>
